[
  {
    "objectID": "version_quarto.html",
    "href": "version_quarto.html",
    "title": "Proyecto rendimiento de estudiantes",
    "section": "",
    "text": "En este proyecto, analizaremos un conjunto de datos de rendimiento de estudiantes con el objetivo de predecir el puntaje del examen de los estudiantes para generar un impacto en el rendimiento de los alumnos en el caso de que su rendimiento en los exámenes sea mejor compartiendo insights para la mejora del rendimiento del estudiante y se reduzca la posibilidad de desaprobar el examen."
  },
  {
    "objectID": "version_quarto.html#definir-problema",
    "href": "version_quarto.html#definir-problema",
    "title": "Proyecto rendimiento de estudiantes",
    "section": "",
    "text": "En este proyecto, analizaremos un conjunto de datos de rendimiento de estudiantes con el objetivo de predecir el puntaje del examen de los estudiantes para generar un impacto en el rendimiento de los alumnos en el caso de que su rendimiento en los exámenes sea mejor compartiendo insights para la mejora del rendimiento del estudiante y se reduzca la posibilidad de desaprobar el examen."
  },
  {
    "objectID": "version_quarto.html#recopilación-de-datos",
    "href": "version_quarto.html#recopilación-de-datos",
    "title": "Proyecto rendimiento de estudiantes",
    "section": "2. Recopilación de datos",
    "text": "2. Recopilación de datos\n\n\nCode\n# Importación de librerías\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nimport warnings\nwarnings.filterwarnings('ignore', category=FutureWarning)\n\n\n# Carga de datos\ndf = pd.read_csv('data.csv', sep=\",\")\n\n# Resumen estadístico\n# Mostrar las primeras filas del dataset\nprint(\"Primeras filas del dataset:\")\nprint(df.head())\n\n# Mostrar información general del dataset\nprint(\"\\nInformación del dataset:\")\nprint(df.info())\n\n# Descripción estadística básica del dataset\nprint(\"\\nDescripción estadística:\")\nprint(df.describe())\n\ninfo = df.shape\nprint(\"\\nLa cantidad de filas y columnas en nuestro dataframe es de:\",info)\n\ntipos = df.dtypes\nprint(\"\\nTipos de datos presentes en el dataset:\\n\",tipos)\n\n\nPrimeras filas del dataset:\n   Hours_Studied  Attendance Parental_Involvement Access_to_Resources  \\\n0             23          84                  Low                High   \n1             19          64                  Low              Medium   \n2             24          98               Medium              Medium   \n3             29          89                  Low              Medium   \n4             19          92               Medium              Medium   \n\n  Extracurricular_Activities  Sleep_Hours  Previous_Scores Motivation_Level  \\\n0                         No            7               73              Low   \n1                         No            8               59              Low   \n2                        Yes            7               91           Medium   \n3                        Yes            8               98           Medium   \n4                        Yes            6               65           Medium   \n\n  Internet_Access  Tutoring_Sessions Family_Income Teacher_Quality  \\\n0             Yes                  0           Low          Medium   \n1             Yes                  2        Medium          Medium   \n2             Yes                  2        Medium          Medium   \n3             Yes                  1        Medium          Medium   \n4             Yes                  3        Medium            High   \n\n  School_Type Peer_Influence  Physical_Activity Learning_Disabilities  \\\n0      Public       Positive                  3                    No   \n1      Public       Negative                  4                    No   \n2      Public        Neutral                  4                    No   \n3      Public       Negative                  4                    No   \n4      Public        Neutral                  4                    No   \n\n  Parental_Education_Level Distance_from_Home  Gender  Exam_Score  \n0              High School               Near    Male          67  \n1                  College           Moderate  Female          61  \n2             Postgraduate               Near    Male          74  \n3              High School           Moderate    Male          71  \n4                  College               Near  Female          70  \n\nInformación del dataset:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 6607 entries, 0 to 6606\nData columns (total 20 columns):\n #   Column                      Non-Null Count  Dtype \n---  ------                      --------------  ----- \n 0   Hours_Studied               6607 non-null   int64 \n 1   Attendance                  6607 non-null   int64 \n 2   Parental_Involvement        6607 non-null   object\n 3   Access_to_Resources         6607 non-null   object\n 4   Extracurricular_Activities  6607 non-null   object\n 5   Sleep_Hours                 6607 non-null   int64 \n 6   Previous_Scores             6607 non-null   int64 \n 7   Motivation_Level            6607 non-null   object\n 8   Internet_Access             6607 non-null   object\n 9   Tutoring_Sessions           6607 non-null   int64 \n 10  Family_Income               6607 non-null   object\n 11  Teacher_Quality             6529 non-null   object\n 12  School_Type                 6607 non-null   object\n 13  Peer_Influence              6607 non-null   object\n 14  Physical_Activity           6607 non-null   int64 \n 15  Learning_Disabilities       6607 non-null   object\n 16  Parental_Education_Level    6517 non-null   object\n 17  Distance_from_Home          6540 non-null   object\n 18  Gender                      6607 non-null   object\n 19  Exam_Score                  6607 non-null   int64 \ndtypes: int64(7), object(13)\nmemory usage: 1.0+ MB\nNone\n\nDescripción estadística:\n       Hours_Studied   Attendance  Sleep_Hours  Previous_Scores  \\\ncount    6607.000000  6607.000000   6607.00000      6607.000000   \nmean       19.975329    79.977448      7.02906        75.070531   \nstd         5.990594    11.547475      1.46812        14.399784   \nmin         1.000000    60.000000      4.00000        50.000000   \n25%        16.000000    70.000000      6.00000        63.000000   \n50%        20.000000    80.000000      7.00000        75.000000   \n75%        24.000000    90.000000      8.00000        88.000000   \nmax        44.000000   100.000000     10.00000       100.000000   \n\n       Tutoring_Sessions  Physical_Activity   Exam_Score  \ncount        6607.000000        6607.000000  6607.000000  \nmean            1.493719           2.967610    67.235659  \nstd             1.230570           1.031231     3.890456  \nmin             0.000000           0.000000    55.000000  \n25%             1.000000           2.000000    65.000000  \n50%             1.000000           3.000000    67.000000  \n75%             2.000000           4.000000    69.000000  \nmax             8.000000           6.000000   101.000000  \n\nLa cantidad de filas y columnas en nuestro dataframe es de: (6607, 20)\n\nTipos de datos presentes en el dataset:\n Hours_Studied                  int64\nAttendance                     int64\nParental_Involvement          object\nAccess_to_Resources           object\nExtracurricular_Activities    object\nSleep_Hours                    int64\nPrevious_Scores                int64\nMotivation_Level              object\nInternet_Access               object\nTutoring_Sessions              int64\nFamily_Income                 object\nTeacher_Quality               object\nSchool_Type                   object\nPeer_Influence                object\nPhysical_Activity              int64\nLearning_Disabilities         object\nParental_Education_Level      object\nDistance_from_Home            object\nGender                        object\nExam_Score                     int64\ndtype: object"
  },
  {
    "objectID": "version_quarto.html#análisis-de-datos-por-variable",
    "href": "version_quarto.html#análisis-de-datos-por-variable",
    "title": "Proyecto rendimiento de estudiantes",
    "section": "3. Análisis de datos por Variable",
    "text": "3. Análisis de datos por Variable"
  },
  {
    "objectID": "version_quarto.html#análisis-de-datos-cuantitativos",
    "href": "version_quarto.html#análisis-de-datos-cuantitativos",
    "title": "Proyecto rendimiento de estudiantes",
    "section": "Análisis de datos cuantitativos",
    "text": "Análisis de datos cuantitativos\n\n\nCode\n# Función para el análisis univariado de variables cuantitativas\ndef analizar_variable_cuantitativa(df, columna):\n    mean = np.mean(df[columna])\n    median = np.median(df[columna])\n    std = np.std(df[columna])\n    min_value = np.min(df[columna])\n    max_value = np.max(df[columna])\n\n    print(f\"Análisis de la Variable '{columna}'\")\n    print(f\"Media: {mean:.2f}\")\n    print(f\"Mediana: {median:.2f}\")\n    print(f\"Desviación Estándar: {std:.2f}\")\n    print(f\"Valor Mínimo: {min_value:.2f}\")\n    print(f\"Valor Máximo: {max_value:.2f}\")\n    print(\"\\n\")\n\n    # Visualización de la distribución (Histograma con KDE)\n    plt.figure(figsize=(10, 6))\n    sns.histplot(df[columna], bins=30, kde=True, color='#4C72B0')\n    plt.title(f'Distribución de {columna}')\n    plt.xlabel(columna)\n    plt.ylabel('Frecuencia')\n    plt.show()\n\n# Aplicar la función a todas las columnas numéricas del dataframe\ncolumnas_cuantitativas = df.select_dtypes(include=['int64', 'float64']).columns\nfor columna in columnas_cuantitativas:\n    analizar_variable_cuantitativa(df, columna)\n\n\nAnálisis de la Variable 'Hours_Studied'\nMedia: 19.98\nMediana: 20.00\nDesviación Estándar: 5.99\nValor Mínimo: 1.00\nValor Máximo: 44.00\n\n\n\n\n\n\n\n\n\n\n\nAnálisis de la Variable 'Attendance'\nMedia: 79.98\nMediana: 80.00\nDesviación Estándar: 11.55\nValor Mínimo: 60.00\nValor Máximo: 100.00\n\n\n\n\n\n\n\n\n\n\n\nAnálisis de la Variable 'Sleep_Hours'\nMedia: 7.03\nMediana: 7.00\nDesviación Estándar: 1.47\nValor Mínimo: 4.00\nValor Máximo: 10.00\n\n\n\n\n\n\n\n\n\n\n\nAnálisis de la Variable 'Previous_Scores'\nMedia: 75.07\nMediana: 75.00\nDesviación Estándar: 14.40\nValor Mínimo: 50.00\nValor Máximo: 100.00\n\n\n\n\n\n\n\n\n\n\n\nAnálisis de la Variable 'Tutoring_Sessions'\nMedia: 1.49\nMediana: 1.00\nDesviación Estándar: 1.23\nValor Mínimo: 0.00\nValor Máximo: 8.00\n\n\n\n\n\n\n\n\n\n\n\nAnálisis de la Variable 'Physical_Activity'\nMedia: 2.97\nMediana: 3.00\nDesviación Estándar: 1.03\nValor Mínimo: 0.00\nValor Máximo: 6.00\n\n\n\n\n\n\n\n\n\n\n\nAnálisis de la Variable 'Exam_Score'\nMedia: 67.24\nMediana: 67.00\nDesviación Estándar: 3.89\nValor Mínimo: 55.00\nValor Máximo: 101.00"
  },
  {
    "objectID": "version_quarto.html#análisis-de-datos-cualitativos",
    "href": "version_quarto.html#análisis-de-datos-cualitativos",
    "title": "Proyecto rendimiento de estudiantes",
    "section": "Análisis de datos cualitativos",
    "text": "Análisis de datos cualitativos\n\n\nCode\n# Función para el análisis univariado de variables categóricas\ndef analizar_variable_categorica(df, columna):\n    values_counts = df[columna].value_counts()\n    moda = values_counts.idxmax()\n\n    print(f\"Análisis Univariado de la Variable '{columna}'\")\n    print(f\"Frecuencia de las categorías:\\n{values_counts}\")\n    print(f\"Moda (Categoría más frecuente): {moda}\")\n    print(\"\\n\")\n\n    # Visualización de la distribución\n    plt.figure(figsize=(10, 6))\n    sns.countplot(\n        x=columna, \n        data=df[df[columna].isin(values_counts.index)], \n        order=values_counts.index, \n        palette='Set2'\n    )\n    plt.title(f'Distribución de {columna}')\n    plt.xlabel(columna)\n    plt.ylabel('Frecuencia')\n    plt.xticks(rotation=45)\n    plt.show()\n\n# Aplicar la función a todas las columnas categóricas del dataframe\ncolumnas_categoricas = df.select_dtypes(include=['object']).columns\nfor columna in columnas_categoricas:\n    analizar_variable_categorica(df, columna)\n\n\nAnálisis Univariado de la Variable 'Parental_Involvement'\nFrecuencia de las categorías:\nParental_Involvement\nMedium    3362\nHigh      1908\nLow       1337\nName: count, dtype: int64\nModa (Categoría más frecuente): Medium\n\n\n\n\n\n\n\n\n\n\n\nAnálisis Univariado de la Variable 'Access_to_Resources'\nFrecuencia de las categorías:\nAccess_to_Resources\nMedium    3319\nHigh      1975\nLow       1313\nName: count, dtype: int64\nModa (Categoría más frecuente): Medium\n\n\n\n\n\n\n\n\n\n\n\nAnálisis Univariado de la Variable 'Extracurricular_Activities'\nFrecuencia de las categorías:\nExtracurricular_Activities\nYes    3938\nNo     2669\nName: count, dtype: int64\nModa (Categoría más frecuente): Yes\n\n\n\n\n\n\n\n\n\n\n\nAnálisis Univariado de la Variable 'Motivation_Level'\nFrecuencia de las categorías:\nMotivation_Level\nMedium    3351\nLow       1937\nHigh      1319\nName: count, dtype: int64\nModa (Categoría más frecuente): Medium\n\n\n\n\n\n\n\n\n\n\n\nAnálisis Univariado de la Variable 'Internet_Access'\nFrecuencia de las categorías:\nInternet_Access\nYes    6108\nNo      499\nName: count, dtype: int64\nModa (Categoría más frecuente): Yes\n\n\n\n\n\n\n\n\n\n\n\nAnálisis Univariado de la Variable 'Family_Income'\nFrecuencia de las categorías:\nFamily_Income\nLow       2672\nMedium    2666\nHigh      1269\nName: count, dtype: int64\nModa (Categoría más frecuente): Low\n\n\n\n\n\n\n\n\n\n\n\nAnálisis Univariado de la Variable 'Teacher_Quality'\nFrecuencia de las categorías:\nTeacher_Quality\nMedium    3925\nHigh      1947\nLow        657\nName: count, dtype: int64\nModa (Categoría más frecuente): Medium\n\n\n\n\n\n\n\n\n\n\n\nAnálisis Univariado de la Variable 'School_Type'\nFrecuencia de las categorías:\nSchool_Type\nPublic     4598\nPrivate    2009\nName: count, dtype: int64\nModa (Categoría más frecuente): Public\n\n\n\n\n\n\n\n\n\n\n\nAnálisis Univariado de la Variable 'Peer_Influence'\nFrecuencia de las categorías:\nPeer_Influence\nPositive    2638\nNeutral     2592\nNegative    1377\nName: count, dtype: int64\nModa (Categoría más frecuente): Positive\n\n\n\n\n\n\n\n\n\n\n\nAnálisis Univariado de la Variable 'Learning_Disabilities'\nFrecuencia de las categorías:\nLearning_Disabilities\nNo     5912\nYes     695\nName: count, dtype: int64\nModa (Categoría más frecuente): No\n\n\n\n\n\n\n\n\n\n\n\nAnálisis Univariado de la Variable 'Parental_Education_Level'\nFrecuencia de las categorías:\nParental_Education_Level\nHigh School     3223\nCollege         1989\nPostgraduate    1305\nName: count, dtype: int64\nModa (Categoría más frecuente): High School\n\n\n\n\n\n\n\n\n\n\n\nAnálisis Univariado de la Variable 'Distance_from_Home'\nFrecuencia de las categorías:\nDistance_from_Home\nNear        3884\nModerate    1998\nFar          658\nName: count, dtype: int64\nModa (Categoría más frecuente): Near\n\n\n\n\n\n\n\n\n\n\n\nAnálisis Univariado de la Variable 'Gender'\nFrecuencia de las categorías:\nGender\nMale      3814\nFemale    2793\nName: count, dtype: int64\nModa (Categoría más frecuente): Male"
  },
  {
    "objectID": "version_quarto.html#verificar-si-hay-patrones-o-relaciones-presentes-entre-variables",
    "href": "version_quarto.html#verificar-si-hay-patrones-o-relaciones-presentes-entre-variables",
    "title": "Proyecto rendimiento de estudiantes",
    "section": "Verificar si hay patrones o relaciones presentes entre variables",
    "text": "Verificar si hay patrones o relaciones presentes entre variables\n\n\nCode\nsns.scatterplot(x='Hours_Studied', y='Exam_Score', data=df)\nplt.title('Relación entre Horas de Estudio y Puntuación de Examen')\nplt.xlabel('Horas de Estudio')\nplt.ylabel('Puntuación de Examen')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nsns.scatterplot(x='Attendance', y='Exam_Score', data=df)\nplt.title('Relación entre Horas de Estudio y Puntuación de Examen')\nplt.xlabel('Horas de Estudio')\nplt.ylabel('Puntuación de Examen')\nplt.show()"
  },
  {
    "objectID": "version_quarto.html#verificar-si-hay-valores-nulos-en-el-dataset",
    "href": "version_quarto.html#verificar-si-hay-valores-nulos-en-el-dataset",
    "title": "Proyecto rendimiento de estudiantes",
    "section": "Verificar si hay valores nulos en el dataset",
    "text": "Verificar si hay valores nulos en el dataset\n\nCorrección de valores nulos presentes en el dataset\n\n\nCode\nprint(\"\\nValores nulos por columna:\")\nprint(df.isnull().sum())\n\n\n\nValores nulos por columna:\nHours_Studied                  0\nAttendance                     0\nParental_Involvement           0\nAccess_to_Resources            0\nExtracurricular_Activities     0\nSleep_Hours                    0\nPrevious_Scores                0\nMotivation_Level               0\nInternet_Access                0\nTutoring_Sessions              0\nFamily_Income                  0\nTeacher_Quality               78\nSchool_Type                    0\nPeer_Influence                 0\nPhysical_Activity              0\nLearning_Disabilities          0\nParental_Education_Level      90\nDistance_from_Home            67\nGender                         0\nExam_Score                     0\ndtype: int64\n\n\n\n\nCode\n# Lista de las columnas categóricas que deseas reemplazar por la moda\ncategorical_columns = ['Parental_Education_Level', 'Distance_from_Home', 'Teacher_Quality']\n\n# Iterar sobre cada columna y reemplazar los valores nulos con la moda\nfor column in categorical_columns:\n    mode_value = df[column].mode()[0]  # Obtener la moda (el valor más frecuente)\n    df[column].fillna(mode_value, inplace=True)\n    print(f\"Valores nulos en '{column}' reemplazados por la moda: '{mode_value}'\")\n\n\nValores nulos en 'Parental_Education_Level' reemplazados por la moda: 'High School'\nValores nulos en 'Distance_from_Home' reemplazados por la moda: 'Near'\nValores nulos en 'Teacher_Quality' reemplazados por la moda: 'Medium'"
  },
  {
    "objectID": "version_quarto.html#preparación-de-datos",
    "href": "version_quarto.html#preparación-de-datos",
    "title": "Proyecto rendimiento de estudiantes",
    "section": "Preparación de datos",
    "text": "Preparación de datos\n\nVamos a realizar el tratamiento de datos pasos a realizar\n\n\nConvertir datos categóricos a numéricos para esto vamos a aplicar one hot encoder y label conder dependiendo a tipo de dato\n\n\nAdemás de convertir los datos categóricos en general para aplicar estos datos en modelos de machine learning, además de verificar el balanceo de datos y aplicación de técnicas para corregir variables con outlayers\n\n\nCode\nfor column in df.columns:\n    unique_values = df[column].unique()\n    print(f\"Valores únicos en la columna '{column}':\")\n    print(unique_values)\n    print(\"\\n------------------------------------\\n\")\n\n\nValores únicos en la columna 'Hours_Studied':\n[23 19 24 29 25 17 21  9 10 14 22 15 12 20 11 13 16 18 31  8 26 28  4 35\n 27 33 36 43 34  1 30  7 32  6 38  5  3  2 39 37 44]\n\n------------------------------------\n\nValores únicos en la columna 'Attendance':\n[ 84  64  98  89  92  88  78  94  80  97  83  82  68  60  70  75  99  74\n  65  62  91  90  66  69  72  63  61  86  77  71  67  87  73  96 100  81\n  95  79  85  76  93]\n\n------------------------------------\n\nValores únicos en la columna 'Parental_Involvement':\n['Low' 'Medium' 'High']\n\n------------------------------------\n\nValores únicos en la columna 'Access_to_Resources':\n['High' 'Medium' 'Low']\n\n------------------------------------\n\nValores únicos en la columna 'Extracurricular_Activities':\n['No' 'Yes']\n\n------------------------------------\n\nValores únicos en la columna 'Sleep_Hours':\n[ 7  8  6 10  9  5  4]\n\n------------------------------------\n\nValores únicos en la columna 'Previous_Scores':\n[ 73  59  91  98  65  89  68  50  80  71  88  87  97  72  74  70  82  58\n  99  84 100  75  54  90  94  51  57  66  96  93  56  52  63  79  81  69\n  95  60  92  77  62  85  78  64  76  55  86  61  53  83  67]\n\n------------------------------------\n\nValores únicos en la columna 'Motivation_Level':\n['Low' 'Medium' 'High']\n\n------------------------------------\n\nValores únicos en la columna 'Internet_Access':\n['Yes' 'No']\n\n------------------------------------\n\nValores únicos en la columna 'Tutoring_Sessions':\n[0 2 1 3 4 5 6 7 8]\n\n------------------------------------\n\nValores únicos en la columna 'Family_Income':\n['Low' 'Medium' 'High']\n\n------------------------------------\n\nValores únicos en la columna 'Teacher_Quality':\n['Medium' 'High' 'Low']\n\n------------------------------------\n\nValores únicos en la columna 'School_Type':\n['Public' 'Private']\n\n------------------------------------\n\nValores únicos en la columna 'Peer_Influence':\n['Positive' 'Negative' 'Neutral']\n\n------------------------------------\n\nValores únicos en la columna 'Physical_Activity':\n[3 4 2 1 5 0 6]\n\n------------------------------------\n\nValores únicos en la columna 'Learning_Disabilities':\n['No' 'Yes']\n\n------------------------------------\n\nValores únicos en la columna 'Parental_Education_Level':\n['High School' 'College' 'Postgraduate']\n\n------------------------------------\n\nValores únicos en la columna 'Distance_from_Home':\n['Near' 'Moderate' 'Far']\n\n------------------------------------\n\nValores únicos en la columna 'Gender':\n['Male' 'Female']\n\n------------------------------------\n\nValores únicos en la columna 'Exam_Score':\n[ 67  61  74  71  70  66  69  72  68  65  64  60  63  62 100  76  79  73\n  78  89  75  59  86  97  83  84  80  58  94  55  92  82  77 101  88  91\n  99  87  57  96  98  95  85  93  56]\n\n------------------------------------"
  },
  {
    "objectID": "version_quarto.html#labelencoder",
    "href": "version_quarto.html#labelencoder",
    "title": "Proyecto rendimiento de estudiantes",
    "section": "LabelEncoder",
    "text": "LabelEncoder\n\nParental_Involvement, Access_to_Resources, Motivation_Level,Family_Income,Teacher_Quality,Peer_Influence,\n\n\nCode\nle = LabelEncoder()\ndf['Parental_Involvement'] = le.fit_transform(df['Parental_Involvement'].astype(str))\n\ndf['Access_to_Resources'] = le.fit_transform(df['Access_to_Resources'].astype(str))\n\ndf['Motivation_Level'] = le.fit_transform(df['Motivation_Level'].astype(str))\n\ndf['Family_Income'] = le.fit_transform(df['Family_Income'].astype(str))\n\ndf['Teacher_Quality'] = le.fit_transform(df['Teacher_Quality'].astype(str))\n\ndf['Peer_Influence'] = le.fit_transform(df['Peer_Influence'].astype(str))\n\ndf['Parental_Education_Level'] = le.fit_transform(df['Parental_Education_Level'].astype(str))\n\ndf['Distance_from_Home'] = le.fit_transform(df['Distance_from_Home'].astype(str))\n\n# datos sin outlayers\n\ndf_clean['Parental_Involvement'] = le.fit_transform(df_clean['Parental_Involvement'].astype(str))\n\ndf_clean['Access_to_Resources'] = le.fit_transform(df_clean['Access_to_Resources'].astype(str))\n\ndf_clean['Motivation_Level'] = le.fit_transform(df_clean['Motivation_Level'].astype(str))\n\ndf_clean['Family_Income'] = le.fit_transform(df_clean['Family_Income'].astype(str))\n\ndf_clean['Teacher_Quality'] = le.fit_transform(df_clean['Teacher_Quality'].astype(str))\n\ndf_clean['Peer_Influence'] = le.fit_transform(df_clean['Peer_Influence'].astype(str))\n\ndf_clean['Parental_Education_Level'] = le.fit_transform(df_clean['Parental_Education_Level'].astype(str))\n\ndf_clean['Distance_from_Home'] = le.fit_transform(df_clean['Distance_from_Home'].astype(str))"
  },
  {
    "objectID": "version_quarto.html#onehotencoder",
    "href": "version_quarto.html#onehotencoder",
    "title": "Proyecto rendimiento de estudiantes",
    "section": "OneHotEncoder",
    "text": "OneHotEncoder\n\nInternet_Access, Extracurricular_Activities, School_Type, Gender, ,Peer_Influence\n\n\nCode\n# Aplicar One-Hot Encoding\ndf = pd.get_dummies(df, columns=['Extracurricular_Activities'])\ndf = pd.get_dummies(df, columns=['Internet_Access'])\ndf = pd.get_dummies(df, columns=['School_Type'])\ndf = pd.get_dummies(df, columns=['Peer_Influence'])\ndf = pd.get_dummies(df, columns=['Learning_Disabilities'])\ndf = pd.get_dummies(df, columns=['Gender'])\n\n# datos sin outlayers\n\ndf_clean = pd.get_dummies(df_clean, columns=['Extracurricular_Activities'])\ndf_clean = pd.get_dummies(df_clean, columns=['Internet_Access'])\ndf_clean = pd.get_dummies(df_clean, columns=['School_Type'])\ndf_clean = pd.get_dummies(df_clean, columns=['Peer_Influence'])\ndf_clean = pd.get_dummies(df_clean, columns=['Learning_Disabilities'])\ndf_clean = pd.get_dummies(df_clean, columns=['Gender'])\n\n\n\n\nCode\nfor column in df.columns:\n    unique_values = df[column].unique()\n    print(f\"Valores únicos en la columna '{column}':\")\n    print(unique_values)\n    print(\"\\n------------------------------------\\n\")\n\n\nValores únicos en la columna 'Hours_Studied':\n[23 19 24 29 25 17 21  9 10 14 22 15 12 20 11 13 16 18 31  8 26 28  4 35\n 27 33 36 43 34  1 30  7 32  6 38  5  3  2 39 37 44]\n\n------------------------------------\n\nValores únicos en la columna 'Attendance':\n[ 84  64  98  89  92  88  78  94  80  97  83  82  68  60  70  75  99  74\n  65  62  91  90  66  69  72  63  61  86  77  71  67  87  73  96 100  81\n  95  79  85  76  93]\n\n------------------------------------\n\nValores únicos en la columna 'Parental_Involvement':\n[1 2 0]\n\n------------------------------------\n\nValores únicos en la columna 'Access_to_Resources':\n[0 2 1]\n\n------------------------------------\n\nValores únicos en la columna 'Sleep_Hours':\n[ 7  8  6 10  9  5  4]\n\n------------------------------------\n\nValores únicos en la columna 'Previous_Scores':\n[ 73  59  91  98  65  89  68  50  80  71  88  87  97  72  74  70  82  58\n  99  84 100  75  54  90  94  51  57  66  96  93  56  52  63  79  81  69\n  95  60  92  77  62  85  78  64  76  55  86  61  53  83  67]\n\n------------------------------------\n\nValores únicos en la columna 'Motivation_Level':\n[1 2 0]\n\n------------------------------------\n\nValores únicos en la columna 'Tutoring_Sessions':\n[0 2 1 3 4 5 6 7 8]\n\n------------------------------------\n\nValores únicos en la columna 'Family_Income':\n[1 2 0]\n\n------------------------------------\n\nValores únicos en la columna 'Teacher_Quality':\n[2 0 1]\n\n------------------------------------\n\nValores únicos en la columna 'Physical_Activity':\n[3 4 2 1 5 0 6]\n\n------------------------------------\n\nValores únicos en la columna 'Parental_Education_Level':\n[1 0 2]\n\n------------------------------------\n\nValores únicos en la columna 'Distance_from_Home':\n[2 1 0]\n\n------------------------------------\n\nValores únicos en la columna 'Exam_Score':\n[ 67  61  74  71  70  66  69  72  68  65  64  60  63  62 100  76  79  73\n  78  89  75  59  86  97  83  84  80  58  94  55  92  82  77 101  88  91\n  99  87  57  96  98  95  85  93  56]\n\n------------------------------------\n\nValores únicos en la columna 'Extracurricular_Activities_No':\n[ True False]\n\n------------------------------------\n\nValores únicos en la columna 'Extracurricular_Activities_Yes':\n[False  True]\n\n------------------------------------\n\nValores únicos en la columna 'Internet_Access_No':\n[False  True]\n\n------------------------------------\n\nValores únicos en la columna 'Internet_Access_Yes':\n[ True False]\n\n------------------------------------\n\nValores únicos en la columna 'School_Type_Private':\n[False  True]\n\n------------------------------------\n\nValores únicos en la columna 'School_Type_Public':\n[ True False]\n\n------------------------------------\n\nValores únicos en la columna 'Peer_Influence_0':\n[False  True]\n\n------------------------------------\n\nValores únicos en la columna 'Peer_Influence_1':\n[False  True]\n\n------------------------------------\n\nValores únicos en la columna 'Peer_Influence_2':\n[ True False]\n\n------------------------------------\n\nValores únicos en la columna 'Learning_Disabilities_No':\n[ True False]\n\n------------------------------------\n\nValores únicos en la columna 'Learning_Disabilities_Yes':\n[False  True]\n\n------------------------------------\n\nValores únicos en la columna 'Gender_Female':\n[False  True]\n\n------------------------------------\n\nValores únicos en la columna 'Gender_Male':\n[ True False]\n\n------------------------------------\n\n\n\n\n\nCode\n# Calcular la matriz de correlación\ncorr_matrix = df.corr()\n\n# Generar el mapa de calor\nplt.figure(figsize=(10, 8))\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\nplt.title('Mapa de calor de la correlación entre variables')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Calcular la matriz de correlación\ncorrelation_matrix = df.corr()\n\n# Filtrar solo las correlaciones con la variable objetivo\ntarget_corr = correlation_matrix['Exam_Score'].sort_values(ascending=False)\nprint(\"Correlación de cada variable con 'Exam_Score':\\n\", target_corr)\n\n\nCorrelación de cada variable con 'Exam_Score':\n Exam_Score                        1.000000\nAttendance                        0.581072\nHours_Studied                     0.445455\nPrevious_Scores                   0.175079\nTutoring_Sessions                 0.156525\nDistance_from_Home                0.088934\nLearning_Disabilities_No          0.085066\nPeer_Influence_2                  0.081217\nExtracurricular_Activities_Yes    0.064382\nInternet_Access_Yes               0.051475\nParental_Education_Level          0.044574\nPhysical_Activity                 0.027824\nSchool_Type_Private               0.008844\nGender_Female                     0.002032\nGender_Male                      -0.002032\nPeer_Influence_1                 -0.007795\nSchool_Type_Public               -0.008844\nMotivation_Level                 -0.014910\nSleep_Hours                      -0.017022\nFamily_Income                    -0.026484\nInternet_Access_No               -0.051475\nTeacher_Quality                  -0.060824\nExtracurricular_Activities_No    -0.064382\nLearning_Disabilities_Yes        -0.085066\nPeer_Influence_0                 -0.088557\nAccess_to_Resources              -0.090503\nParental_Involvement             -0.094289\nName: Exam_Score, dtype: float64"
  },
  {
    "objectID": "version_quarto.html#predicción-con-datos-atípicos",
    "href": "version_quarto.html#predicción-con-datos-atípicos",
    "title": "Proyecto rendimiento de estudiantes",
    "section": "Predicción con datos atípicos",
    "text": "Predicción con datos atípicos\n\n\nCode\n# Separar las características (X) y la variable objetivo (y)\nX = df.drop(columns=['Exam_Score'])  # Todas las columnas excepto la variable objetivo\ny = df['Exam_Score']  # La variable objetivo\n\n# Dividir el conjunto de datos en conjunto de entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\n# Lista de modelos de regresión para evaluar\nmodels = {\n    \"Regresión Lineal\": LinearRegression(),\n    \"Regresión Ridge\": Ridge(alpha=1.0),\n    \"Regresión Lasso\": Lasso(alpha=0.1),\n    \"Árbol de Decisión\": DecisionTreeRegressor(random_state=42,),\n    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42)\n}\nresults = []\n\n# Entrenar y evaluar cada modelo\nfor model_name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    \n    mae = mean_absolute_error(y_test, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    r2 = r2_score(y_test, y_pred)\n    \n    # Almacenar los resultados\n    results.append({\n        \"Modelo\": model_name,\n        \"MAE\": mae,\n        \"RMSE\": rmse,\n        \"R^2\": r2\n    })\n\n# Convertir los resultados en un DataFrame\nresults_df = pd.DataFrame(results)\n\n# Mostrar los resultados ordenados por R^2\nprint(results_df.sort_values(by=\"R^2\", ascending=False))\n\n\n              Modelo       MAE      RMSE       R^2\n1    Regresión Ridge  1.008253  2.016828  0.701362\n0   Regresión Lineal  1.008252  2.016851  0.701356\n2    Regresión Lasso  1.121145  2.075335  0.683784\n4      Random Forest  1.137155  2.121473  0.669568\n3  Árbol de Decisión  1.819613  3.688704  0.001025\n\n\n\n\nCode\n# Variables utilizadas\nprint(\"Variables utilizadas en el modelo:\")\nprint(X.columns)\n\n\nVariables utilizadas en el modelo:\nIndex(['Hours_Studied', 'Attendance', 'Parental_Involvement',\n       'Access_to_Resources', 'Sleep_Hours', 'Previous_Scores',\n       'Motivation_Level', 'Tutoring_Sessions', 'Family_Income',\n       'Teacher_Quality', 'Physical_Activity', 'Parental_Education_Level',\n       'Distance_from_Home', 'Extracurricular_Activities_No',\n       'Extracurricular_Activities_Yes', 'Internet_Access_No',\n       'Internet_Access_Yes', 'School_Type_Private', 'School_Type_Public',\n       'Peer_Influence_0', 'Peer_Influence_1', 'Peer_Influence_2',\n       'Learning_Disabilities_No', 'Learning_Disabilities_Yes',\n       'Gender_Female', 'Gender_Male'],\n      dtype='object')\n\n\n\n\nCode\n# Separar las variables independientes y la variable objetivo\nX = df.drop(columns=['Exam_Score'])\ny = df['Exam_Score']\n\n# Dividir el conjunto de datos\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\n# Definir los modelos base\nbase_models = [\n    ('linear', LinearRegression()),\n    ('random_forest', RandomForestRegressor(n_estimators=100, random_state=42))\n]\n\n# Definir el modelo meta\nmeta_model = LinearRegression()\n\n# Crear el Stacking Regressor\nstacking_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n\n# Entrenar el modelo\nstacking_model.fit(X_train, y_train)\n\n# Hacer predicciones\ny_pred = stacking_model.predict(X_test)\n\n# Evaluar el modelo\nmae = mean_absolute_error(y_test, y_pred)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nr2 = r2_score(y_test, y_pred)\n\n# Mostrar resultados\nprint(\"Resultados del Stacking Regressor\")\nprint(f\"MAE: {mae:.4f}\")\nprint(f\"RMSE: {rmse:.4f}\")\nprint(f\"R^2: {r2:.4f}\")\n\n\nResultados del Stacking Regressor\nMAE: 0.9709\nRMSE: 1.9767\nR^2: 0.7131"
  },
  {
    "objectID": "version_quarto.html#predicción-sin-datos-atípicos",
    "href": "version_quarto.html#predicción-sin-datos-atípicos",
    "title": "Proyecto rendimiento de estudiantes",
    "section": "Predicción sin datos atípicos",
    "text": "Predicción sin datos atípicos\n\n\nCode\n# Separar las características (X) y la variable objetivo (y)\nX = df_clean.drop(columns=['Exam_Score'])  # Todas las columnas excepto la variable objetivo\ny = df_clean['Exam_Score']  # La variable objetivo\n\n# Dividir el conjunto de datos en conjunto de entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\n# Lista de modelos de regresión para evaluar\nmodels = {\n    \"Regresión Lineal\": LinearRegression(),\n    \"Regresión Ridge\": Ridge(alpha=1.0),\n    \"Regresión Lasso\": Lasso(alpha=0.1),\n    \"Árbol de Decisión\": DecisionTreeRegressor(random_state=42,),\n    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42)\n}\nresults = []\n\n# Entrenar y evaluar cada modelo\nfor model_name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    \n    mae = mean_absolute_error(y_test, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    r2 = r2_score(y_test, y_pred)\n    \n    # Almacenar los resultados\n    results.append({\n        \"Modelo\": model_name,\n        \"MAE\": mae,\n        \"RMSE\": rmse,\n        \"R^2\": r2\n    })\n\n# Convertir los resultados en un DataFrame\nresults_df = pd.DataFrame(results)\n\n# Mostrar los resultados ordenados por R^2\nprint(results_df.sort_values(by=\"R^2\", ascending=False))\n\n\n              Modelo       MAE      RMSE       R^2\n4      Random Forest  0.969800  1.333277  0.841340\n1    Regresión Ridge  0.940106  1.333686  0.841242\n0   Regresión Lineal  0.940094  1.333691  0.841241\n2    Regresión Lasso  1.060642  1.449284  0.812529\n3  Árbol de Decisión  1.510896  2.110449  0.602463\n\n\n\n\nCode\n# Variables utilizadas\nprint(\"Variables utilizadas en el modelo:\")\nprint(X.columns)\n\n\nVariables utilizadas en el modelo:\nIndex(['Hours_Studied', 'Attendance', 'Parental_Involvement',\n       'Access_to_Resources', 'Sleep_Hours', 'Previous_Scores',\n       'Motivation_Level', 'Tutoring_Sessions', 'Family_Income',\n       'Teacher_Quality', 'Physical_Activity', 'Parental_Education_Level',\n       'Distance_from_Home', 'Extracurricular_Activities_No',\n       'Extracurricular_Activities_Yes', 'Internet_Access_No',\n       'Internet_Access_Yes', 'School_Type_Private', 'School_Type_Public',\n       'Peer_Influence_0', 'Peer_Influence_1', 'Peer_Influence_2',\n       'Learning_Disabilities_No', 'Learning_Disabilities_Yes',\n       'Gender_Female', 'Gender_Male'],\n      dtype='object')\n\n\n\n\nCode\n# Separar las variables independientes y la variable objetivo\nX = df_clean.drop(columns=['Exam_Score'])\ny = df_clean['Exam_Score']\n\n# Dividir el conjunto de datos\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\n# Definir los modelos base\nbase_models = [\n    ('linear', LinearRegression()),\n    ('random_forest', RandomForestRegressor(n_estimators=100, random_state=42))\n]\n\n# Definir el modelo meta\nmeta_model = LinearRegression()\n\n# Crear el Stacking Regressor\nstacking_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n\n# Entrenar el modelo\nstacking_model.fit(X_train, y_train)\n\n# Hacer predicciones\ny_pred = stacking_model.predict(X_test)\n\n# Evaluar el modelo\nmae = mean_absolute_error(y_test, y_pred)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nr2 = r2_score(y_test, y_pred)\n\n# Mostrar resultados\nprint(\"Resultados del Stacking Regressor\")\nprint(f\"MAE: {mae:.4f}\")\nprint(f\"RMSE: {rmse:.4f}\")\nprint(f\"R^2: {r2:.4f}\")\n\n\nResultados del Stacking Regressor\nMAE: 0.8760\nRMSE: 1.2578\nR^2: 0.8588"
  },
  {
    "objectID": "version_quarto.html#comparación-de-métricas-de-modelos",
    "href": "version_quarto.html#comparación-de-métricas-de-modelos",
    "title": "Proyecto rendimiento de estudiantes",
    "section": "Comparación de métricas de modelos",
    "text": "Comparación de métricas de modelos\n\nComparación de resultados:\n\nSin Datos Atípicos:\n\n\nLos modelos mejoran su desempeño cuando los datos atípicos han sido ajustados.\n\nStacking Regressor tiene el mejor rendimiento con:\nMAE: 0.8760 (error promedio bajo)\nRMSE: 1.2578 (mejor precisión comparado con los otros modelos)\nR²: 0.8588 (explica el 85.88% de la variabilidad en la variable objetivo)\n\nRandom Forest y Regresión Ridge/Lineal presentan un desempeño similar en términos de MAE y RMSE, pero están ligeramente por debajo del Stacking Regressor.\nRegresión Lasso tiene un poco más de error en comparación con Ridge/Lineal.\nÁrbol de Decisión muestra un rendimiento inferior con un MAE de 1.5109 y un R² de 0.6025, lo cual indica que no es tan eficaz en capturar la relación entre las variables.\n\n\nCon Datos Atípicos:\n\n\nLos modelos se ven significativamente afectados por la presencia de outliers.\n\nStacking Regressor sigue siendo el mejor modelo en este caso, pero sus métricas son peores:\nMAE: 0.9709\nRMSE: 1.9767\nR²: 0.7131 (una caída considerable comparada con el caso sin outliers, indicando que el modelo explica menos la variabilidad de la variable objetivo).\n\nRegresión Ridge/Lineal tienen un MAE de aproximadamente 1.008 y un RMSE de 2.016, indicando que los errores son mayores y su capacidad para predecir disminuye.\nRandom Forest y Lasso también ven una degradación en su rendimiento.\nÁrbol de Decisión se ve severamente afectado, con un R² cercano a 0, lo que sugiere que apenas explica la variabilidad de la variable objetivo.\n\n\n\nConclusiones:\n\nImpacto de los Outliers: Los datos atípicos tienden a distorsionar las predicciones de los modelos, especialmente aquellos que no son robustos a valores extremos, como los árboles de decisión. Esto resulta en una mayor imprecisión (valores de MAE y RMSE más altos) y una menor capacidad de explicación (valores de R² más bajos).\nImportancia del Preprocesamiento: Ajustar los outliers ha mejorado el rendimiento de todos los modelos, especialmente del Stacking Regressor. Esto sugiere que los datos limpios permiten a los modelos captar mejor las relaciones entre las variables.\nMejor Modelo: El Stacking Regressor es claramente superior en ambos casos, pero su desempeño mejora significativamente sin outliers. Este modelo combina la fortaleza de varios algoritmos, lo que le da una ventaja en precisión y estabilidad.\nRidge y Regresión Lineal: Son bastante estables y, aunque no son tan buenos como el Stacking Regressor, funcionan bien al ajustar los outliers."
  }
]